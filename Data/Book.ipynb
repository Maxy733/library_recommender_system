{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cb43669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Detected encoding: UTF-8-SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/yllcb5z507zgp13xy5s9g4d80000gn/T/ipykernel_10291/744922840.py:12: DtypeWarning: Columns (1,2,3,4,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"RawData.csv\", encoding=detected_encoding, on_bad_lines='skip')\n",
      "/var/folders/pf/yllcb5z507zgp13xy5s9g4d80000gn/T/ipykernel_10291/744922840.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved as 'cleaning_book_data.csv' with original language and formatting preserved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# STEP 1: Detect encoding\n",
    "with open(\"RawData.csv\", \"rb\") as f:\n",
    "    raw_data = f.read(50000)\n",
    "    result = chardet.detect(raw_data)\n",
    "    detected_encoding = result['encoding']\n",
    "    print(f\"✅ Detected encoding: {detected_encoding}\")\n",
    "\n",
    "# STEP 2: Load dataset using detected encoding\n",
    "df = pd.read_csv(\"RawData.csv\", encoding=detected_encoding, on_bad_lines='skip')\n",
    "\n",
    "# STEP 3: Ensure required columns exist\n",
    "required_columns = ['ItemNo.', 'Author', 'Title', 'Edition', 'Imprint', 'Date', 'Call No.', 'ISBN']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = ''\n",
    "\n",
    "df = df[required_columns]\n",
    "\n",
    "# STEP 4: Drop rows missing essential info\n",
    "df.dropna(subset=['Title', 'Author'], inplace=True)\n",
    "\n",
    "# STEP 5: Fill missing optional fields\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# STEP 6: Remove duplicates\n",
    "df.drop_duplicates(subset=['ItemNo.', 'Title', 'Author'], inplace=True)\n",
    "\n",
    "# STEP 7: Save cleaned file\n",
    "df.to_csv(\"cleaning_book_data.csv\", index=False, encoding=detected_encoding)\n",
    "print(\"✅ Cleaned dataset saved as 'cleaning_book_data.csv' with original language and formatting preserved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
